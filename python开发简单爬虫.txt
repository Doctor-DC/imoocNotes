爬虫调度端：启动、停止爬虫、见识爬虫的运行情况。

爬虫程序的模块：
1： URL管理器：对将要爬取和已经爬取的URL进行管理。可以再次去初一的待爬取的URL将其传给网页下载器；
2： 网页下载器：将URL指定的网页下载下来存储成一个字符串，传送给网页解析器；
3： 网页解析器：解析出有价值的数据，每一个网页都有很多指向其他网页的URL，被解析出来之后可以补充进URL管理器
只要有相关联的URL，爬虫就会一直运行下去。
4：调度器

url管理器
set()
因为set内元素不允许重复
mysql
url+标志位
缓存数据库
redis+set

网页下载器
urllib2 requests

urlib2下载网页下载器

1：
import urllib2
response = urllib2.urlopen('http://www.baidu.com')

print response.getcode()

cont = response.read()

2:添加headers和data
request = urllib2.Request(url)
# request.add_data('a','1')
request.add_header('User-Agent','Mozilla/5.0')

response = urllib2.urlopen(request)
print response.getcode()

3：添加特殊情景的处理器
httpcookieprocessor proxyhandler httpshandler httpredirecthandler

opener = urlib2.build_opener(handler)

urllib2.install_opener(opener)

urllib2.urlopen(url)
urllib2.urlopen(request)

入口页
url格式
目标 标题/简介

页面编码

